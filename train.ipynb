{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZFNXfUcN-j_"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Ac7b-EEMbFws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!cd transformers\n"
      ],
      "metadata": {
        "id": "eNufSlebS90D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env DATA_DIR=/content/Squad1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw68ske4Q1pM",
        "outputId": "5a07a852-e5b3-4f1b-e5c6-ab63a5661b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: DATA_DIR=/content/Squad1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P $DATA_DIR https://raw.githubusercontent.com/TQuad/turkish-nlp-qa-dataset/master/dev-v0.1.json\n",
        "!wget -P $DATA_DIR https://raw.githubusercontent.com/TQuad/turkish-nlp-qa-dataset/master/train-v0.1.json\n",
        "!wget -P $DATA_DIR https://raw.githubusercontent.com/kuzgnlar/datasets/master/question-answer/kuzgunlar_data.json\n",
        "\n",
        "!wget -P $DATA_DIR https://raw.githubusercontent.com/okanvk/Turkish-Reading-Comprehension-Question-Answering-Dataset/master/data/2018%20%2B%202020%20veri%20k%C3%BCmesi/final_dev_data_v2.json\n",
        "!wget -P $DATA_DIR https://raw.githubusercontent.com/okanvk/Turkish-Reading-Comprehension-Question-Answering-Dataset/master/data/2018%20%2B%202020%20veri%20k%C3%BCmesi/final_train_data_v2.json"
      ],
      "metadata": {
        "id": "VXTYUAQiOgls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmd = [\n",
        "       'python', \n",
        "#    '-m torch.distributed.launch --nproc_per_node 2', # use this to perform distributed training over multiple GPUs\n",
        "    'run_squad.py', \n",
        "    \n",
        "    '--model_type', 'bert',                            # model type (one of the list under \"Pick a Model\" above)\n",
        "    \n",
        "    '--model_name_or_path', 'bert-base-tr-qa-v1',       # specific model name of the given model type (shown, a list is here: https://huggingface.co/transformers/pretrained_models.html) \n",
        "                                                       # on first execution this initiates a download of pre-trained model weights;\n",
        "                                                       # can also be a local path to a directory with model weights\n",
        "    \n",
        "    '--output_dir', './models/bert/aybars_checkpoints',        # directory for model checkpoints and predictions\n",
        "    \n",
        "#    '--overwrite_output_dir',                         # use when adding output to a directory that is non-empty --\n",
        "                                                       # for instance, when training crashes midway through and you need to restart it\n",
        "    \n",
        "    '--do_train',                                      # execute the training method \n",
        "    \n",
        "    '--train_file', '$DATA_DIR/train-v0.1.json',       # provide the training data\n",
        "    \n",
        "    # '--version_2_with_negative',                       # ** MUST use this flag if training on SQuAD 2.0! DO NOT use if training on SQuAD 1.1\n",
        "    \n",
        "    # '--do_lower_case',                                 # ** set this flag if using an uncased model; don't use for Cased Models\n",
        "    \n",
        "    # '--do_eval',                                       # execute the evaluation method on the dev set -- note: \n",
        "                                                       # if coupled with --do_train, evaluation runs after fine-tuning \n",
        "    \n",
        "    '--predict_file', '$DATA_DIR/dev-v0.1.json',       # provide evaluation data (dev set)\n",
        "    \n",
        "    '--eval_all_checkpoints',                          # evaluate the model on the dev set at each checkpoint\n",
        "    \n",
        "    '--per_gpu_eval_batch_size', '12',                 # evaluation batch size for each gpu\n",
        "    \n",
        "    '--per_gpu_train_batch_size', '12',                # training batch size for each gpu\n",
        "    \n",
        "    '--save_steps', '5000',                            # how often checkpoints (complete model snapshot) are saved \n",
        "    \n",
        "    '--threads', '8',                                  # num of CPU threads to use for converting SQuAD examples to model features\n",
        "    \n",
        "    # --- Model and Feature Hyperparameters --- \n",
        "    '--num_train_epochs', '2',                         # number of training epochs - usually 2-3 for SQuAD \n",
        "    \n",
        "    '--learning_rate', '3e-5',                         # learning rate for the default optimizer (Adam in this case)\n",
        "    \n",
        "    '--max_seq_length', '512',                         # maximum length allowed for the full input sequence \n",
        "    \n",
        "    '--doc_stride', '128'                              # used for long documents that must be chunked into multiple features -- \n",
        "       ]"
      ],
      "metadata": {
        "id": "lTKOQkvZR2XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/Squad1/dev-v0.1.json\") as dev:\n",
        "  dev_tquad = json.load(dev)\n",
        "\n",
        "with open(\"/content/Squad1/train-v0.1.json\") as train:\n",
        "  train_tquad = json.load(train)\n",
        "\n",
        "def answer_start_to_int(dataset):\n",
        "  for i in range(len(dataset[\"data\"])):\n",
        "    for j in range(len(dataset[\"data\"][i][\"paragraphs\"])):\n",
        "      for k in range(len(dataset[\"data\"][i][\"paragraphs\"][j][\"qas\"])):\n",
        "        for l in range(len(dataset[\"data\"][i][\"paragraphs\"][j][\"qas\"][k][\"answers\"])):\n",
        "          dataset[\"data\"][i][\"paragraphs\"][j][\"qas\"][k][\"answers\"][l][\"answer_start\"] = int(dataset[\"data\"][i][\"paragraphs\"][j][\"qas\"][k][\"answers\"][l][\"answer_start\"])  \n",
        "\n",
        "answer_start_to_int(train_tquad)\n",
        "answer_start_to_int(dev_tquad)\n",
        "\n",
        "train_tquad[\"version\"] = \"v0.1\"\n",
        "dev_tquad[\"version\"] = \"v0.1\"\n",
        "with open(\"/content/Squad1/train-v0.1-wv.json\",\"w\") as train:\n",
        "  json.dump(train_tquad,train)\n",
        "\n",
        "with open(\"/content/Squad1/dev-v0.1-wv.json\",\"w\") as dev:\n",
        "  json.dump(dev_tquad,dev)"
      ],
      "metadata": {
        "id": "qd6BjwOqBv9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR XLM-R\n",
        "!pip install sentencepiece\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK_z8pkyA3-g",
        "outputId": "534b1c74-49a9-4587-8564-8ccdfa8402f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/transformers/examples/legacy/question-answering/run_squad.py  \\\n",
        "    --model_type xlm-roberta   \\\n",
        "    --model_name_or_path xlm-roberta-base  \\\n",
        "    --output_dir /models/bert/ \\\n",
        "    --data_dir /content/Squad1   \\\n",
        "    --overwrite_output_dir \\\n",
        "    --overwrite_cache \\\n",
        "    --do_train  \\\n",
        "    --train_file  /content/Squad1/mixed_train_dataset.json   \\\n",
        "    --do_eval   \\\n",
        "    --predict_file /content/Squad1/mixed_dev_dataset.json  \\\n",
        "    --per_gpu_train_batch_size 8 \\\n",
        "    --learning_rate 3e-5   \\\n",
        "    --num_train_epochs 2.0   \\\n",
        "    --max_seq_length 512   \\\n",
        "    --doc_stride 128   \\\n",
        "    --threads 10   \\\n",
        "    --save_steps 5000 "
      ],
      "metadata": {
        "id": "Dmrvv1TqUiAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python run_squad.py \\\n",
        "#   --model_type bert \\\n",
        "#   --model_name_or_path bert-base-cased \\\n",
        "#   --do_train \\\n",
        "#   --do_eval \\\n",
        "#   --do_lower_case \\\n",
        "#   --train_file $SQUAD_DIR/train-v1.1.json \\\n",
        "#   --predict_file $SQUAD_DIR/dev-v1.1.json \\\n",
        "#   --per_gpu_train_batch_size 12 \\\n",
        "#   --learning_rate 3e-5 \\\n",
        "#   --num_train_epochs 2.0 \\\n",
        "#   --max_seq_length 384 \\\n",
        "#   --doc_stride 128 \\\n",
        "#   --output_dir /tmp/debug_squad/"
      ],
      "metadata": {
        "id": "8suAYJOWgonZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"Aybars/ModelOnWhole\")"
      ],
      "metadata": {
        "id": "OyrF3B8h-9Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/models/bert/\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"/models/bert/\")"
      ],
      "metadata": {
        "id": "LMwarx7WoVrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"I.Murat'ın annesi kimdir?\"\n",
        "\n",
        "context = \"\"\"I.Murat 1326 yılında Bursada doğmuştur. I.Murat 1389 yılında Kosavada ölmüştür.\n",
        "    Osmanlı İmparatorluğu'nun üçüncü padişahı olan I.Murat, 1359 ile 1389 yılları arasında beylik yapmıştır.\n",
        "    I.Murat'ın babası Orhan Gazi, annesi Nilüfer Hatun'dur.\n",
        "    I.Murat babası Orhan Gazi döneminde 95.000 kilometrekare olarak almış, devlet topraklarını I.Murat döneminde topraklarını yaklaşık 500.000 kilometrekareye genişlemiştir.\n",
        "    1362 yılında Ankara Eratna beyliğinden yeniden alınmıştır.\n",
        "    1362 yılında Sazlıdere savaşı ile gerçekleşmiştir. Sazlıdere savaşı sonucunda Edirne ve Filibe alınmıştır. Sazlıdere savaşı Osmanlı devleti ile Bizans ve Bulgar güçleri arasında gerçekleşmiştir.\n",
        "    Hamitoğullarından Eğridir ve çevresi satın alındı.\n",
        "    1364 yılında Sırpsındığı savaşı gerçekleşti. Balkan devletlerinden oluşan haçlı ordusunun başında Sırp Kralı I.Layoş vardı.\n",
        "    Haçlı ordusu, Hacı İlbeyi tarafından yapılan ani bir baskın ile yok edilmiştir.\n",
        "    Sırpsındığı savaşından sonra Edirne başkent yapılmıştır.\n",
        "    Sırpsındığı savaşı Osmanlıların Balkanlarda haçlılarla yaptığı ilk savaştır.\n",
        "    Bulgar krallığı Sırpsındığı savaşı sonrası Osmanlı Devletine bağlanmıştır.\n",
        "    1371 yılında Çirmen savaşı gerçekleşti. Çirmen savaşı Evranos Bey ile Sırplar arasında olmuştur. Çirmen Savaşını Osmanlı Devleti kazanmıştır.\n",
        "    Çirmen savaşı sonucunda Makedonya'nın bir kısmı alındı.\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "UKHIHA_RonEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "question_answerer = pipeline(\"question-answering\",model = \"/models/bert\",tokenizer = tokenizer)"
      ],
      "metadata": {
        "id": "dzqHODbYo0ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer(question,context)"
      ],
      "metadata": {
        "id": "w_tGBjSmpE_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39cc6911-5b1f-44a5-f552-d7ea8b64cb50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': \"annesi Nilüfer Hatun'dur.\",\n",
              " 'end': 248,\n",
              " 'score': 0.4678921103477478,\n",
              " 'start': 223}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/bert_folder.zip  /models\n",
        "\n"
      ],
      "metadata": {
        "id": "IEZPfDGNxlZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/bert_folder.zip\")"
      ],
      "metadata": {
        "id": "mwiwzsucVzuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# whole\n",
        "!python /content/transformers/examples/legacy/question-answering/run_squad.py  \\\n",
        "    --model_type  bert  \\\n",
        "    --model_name_or_path Aybars/ModelOnTquad \\\n",
        "    --output_dir /models_eval/bert/ \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_eval   \\\n",
        "    --overwrite_cache \\\n",
        "    --predict_file /content/Squad1/whole_dev_dataset.json \\\n",
        "    --per_gpu_eval_batch_size 8 \\\n",
        "    --learning_rate 3e-5   \\\n",
        "    --max_seq_length 512   \\\n",
        "    --doc_stride 128   \\\n",
        "    --threads 10   \\\n",
        "    --save_steps 5000 "
      ],
      "metadata": {
        "id": "ZhFUhxGDXpol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Okanvk\n",
        "!python /content/transformers/examples/legacy/question-answering/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path Aybars/ModelOnTquad \\\n",
        "    --output_dir /models_eval2/bert/ \\\n",
        "    --overwrite_output_dir \\\n",
        "    --overwrite_cache \\\n",
        "    --do_eval   \\\n",
        "    --predict_file /content/Squad1/final_dev_data_v2.json \\\n",
        "    --per_gpu_eval_batch_size 8 \\\n",
        "    --learning_rate 3e-5   \\\n",
        "    --max_seq_length 512   \\\n",
        "    --doc_stride 128   \\\n",
        "    --threads 10   \\\n",
        "    --save_steps 5000 "
      ],
      "metadata": {
        "id": "JAVo4lTaYvmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluating Our model in different dev_datas\n",
        "# TQUAD\n",
        "!python /content/transformers/examples/legacy/question-answering/run_squad.py  \\\n",
        "    --model_type bert  \\\n",
        "    --model_name_or_path Aybars/ModelOnTquad \\\n",
        "    --output_dir /models_eval/bert/ \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_eval   \\\n",
        "    --overwrite_cache \\\n",
        "    --predict_file /content/Squad1/dev-v0.1-wv.json \\\n",
        "    --per_gpu_eval_batch_size 8 \\\n",
        "    --learning_rate 3e-5   \\\n",
        "    --max_seq_length 512   \\\n",
        "    --doc_stride 128   \\\n",
        "    --threads 10   \\\n",
        "    --save_steps 5000 "
      ],
      "metadata": {
        "id": "6hzNEQXkW8-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xquad.tr\n",
        "!python /content/transformers/examples/legacy/question-answering/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path  Aybars/ModelOnTquad \\\n",
        "    --output_dir /models_eval3/bert/ \\\n",
        "    --overwrite_output_dir \\\n",
        "    --overwrite_cache \\\n",
        "    --do_eval   \\\n",
        "    --predict_file /content/Squad1/xquad.tr.json \\\n",
        "    --per_gpu_eval_batch_size 8 \\\n",
        "    --learning_rate 3e-5   \\\n",
        "    --max_seq_length 512   \\\n",
        "    --doc_stride 128   \\\n",
        "    --threads 10   \\\n",
        "    --save_steps 5000 "
      ],
      "metadata": {
        "id": "JABle7oaegJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Pushing Model to the hub\n",
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!sudo apt-get install git-lfs\n",
        "!git lfs install"
      ],
      "metadata": {
        "id": "1MAZZo0G225_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "xtNd2ZyO3gCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(repo_path_or_name=\"XLM_Turkish\",use_auth_token =\"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\")"
      ],
      "metadata": {
        "id": "KvxSShxb4FX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.push_to_hub(repo_path_or_name=\"XLM_Turkish\",use_auth_token =\"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\")"
      ],
      "metadata": {
        "id": "q-n3-oza77oD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}