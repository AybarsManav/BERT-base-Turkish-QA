{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenerativeQA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab,faiss,ocr]"
      ],
      "metadata": {
        "id": "Ph-M35yQELg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import requests\n",
        "import pandas as pd\n",
        "from haystack import Document\n",
        "from haystack.document_stores import FAISSDocumentStore\n",
        "from haystack.nodes import RAGenerator, DensePassageRetriever"
      ],
      "metadata": {
        "id": "3Zo8Qk0jEhST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget --no-check-certificate https://dl.xpdfreader.com/xpdf-tools-linux-4.03.tar.gz\n",
        "!tar -xvf xpdf-tools-linux-4.03.tar.gz && sudo cp xpdf-tools-linux-4.03/bin64/pdftotext/usr /local/bin"
      ],
      "metadata": {
        "id": "D9_bx0s4Enna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import TextConverter, PDFToTextConverter, DocxToTextConverter, PreProcessor\n",
        "from haystack.utils import convert_files_to_dicts, fetch_archive_from_http"
      ],
      "metadata": {
        "id": "llaXkL-WE1tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_docs = convert_files_to_dicts(\"Data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z4YPjIMPDrX",
        "outputId": "6b18dd71-c9fa-482a-ed72-2ad2c9087efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - haystack.utils.preprocessing -  Converting Data/AybarsManavHW2.docx\n",
            "INFO - haystack.utils.preprocessing -  Converting Data/Textfile.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = PreProcessor(\n",
        "    clean_empty_lines=True,\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=False,\n",
        "    split_by=\"word\",\n",
        "    split_length=100,\n",
        "    split_respect_sentence_boundary=True\n",
        ")"
      ],
      "metadata": {
        "id": "hN8vJuKgPpG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = preprocessor.process(all_docs)\n",
        "\n",
        "print(f\"n_files_input: {len(all_docs)}\\nn_docs_output: {len(docs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmr5bk1FPtCm",
        "outputId": "7ae5db4b-d466-4203-ccfc-58b0e9c3fd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 955.97docs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_files_input: 2\n",
            "n_docs_output: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_store = FAISSDocumentStore(\n",
        "    faiss_index_factory_str=\"Flat\",\n",
        "    return_embedding=True\n",
        ")\n",
        "#initializing FAISS Document Store"
      ],
      "metadata": {
        "id": "7-4P79i1QAKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing DPR Retriever\n",
        "retriever = DensePassageRetriever(\n",
        "    document_store=document_store,\n",
        "    query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
        "    passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
        "    use_gpu=True,\n",
        "    embed_title=True,\n",
        ")"
      ],
      "metadata": {
        "id": "W4sarrtkQL_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing RAG Generator\n",
        "generator = RAGenerator(\n",
        "    model_name_or_path=\"facebook/rag-token-nq\",\n",
        "    use_gpu=True,\n",
        "    top_k=1,\n",
        "    max_length=200,\n",
        "    min_length=2,\n",
        "    embed_title=True,\n",
        "    num_beams=2,\n",
        ")"
      ],
      "metadata": {
        "id": "42t-5iq9QXw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_store.write_documents(docs)\n",
        "document_store.update_embeddings(retriever = retriever)"
      ],
      "metadata": {
        "id": "UYf08PkZQbON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import GenerativeQAPipeline\n",
        "from haystack.utils import print_answers"
      ],
      "metadata": {
        "id": "XU25ZFujRBGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = GenerativeQAPipeline(generator = generator, retriever = retriever)\n",
        "res = pipe.run(query = \"what increasing the expected value and variance results in \",  params={\"Generator\": {\"top_k\": 1}, \"Retriever\": {\"top_k\": 5}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpF42Oz4RIfu",
        "outputId": "7df7c21a-bf14-43af-cadc-ae960594dd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/rag/tokenization_rag.py:97: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1749: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList(MaxLengthCriteria(max_length=max_length))` instead.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_answers(res, details=\"minimum\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPynJJGtRhKn",
        "outputId": "35d00232-2a4b-4ec5-f84c-c4da86772387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: what increasing the expected value and variance results in \n",
            "Answers:\n",
            "[{'answer': ' increase in standard deviation'}]\n"
          ]
        }
      ]
    }
  ]
}